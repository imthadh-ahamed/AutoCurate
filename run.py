"""
Run AutoCurate Application
Main entry point with different run modes
"""

import os
import sys
import argparse
import asyncio
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent))

def run_api():
    """Run the FastAPI application"""
    import uvicorn
    from src.config.settings import settings
    
    print("ğŸš€ Starting AutoCurate API Server...")
    print(f"ğŸ“¡ Server will be available at: http://{settings.app.host}:{settings.app.port}")
    print(f"ğŸ“š API Documentation: http://{settings.app.host}:{settings.app.port}/docs")
    
    uvicorn.run(
        "src.main:app",
        host=settings.app.host,
        port=settings.app.port,
        reload=settings.app.debug,
        log_level=settings.app.log_level.lower()
    )


def run_worker():
    """Run Celery worker"""
    print("ğŸ”§ Starting AutoCurate Celery Worker...")
    os.system("celery -A src.celery_app worker --loglevel=info")


def run_scheduler():
    """Run Celery beat scheduler"""
    print("â° Starting AutoCurate Task Scheduler...")
    os.system("celery -A src.celery_app beat --loglevel=info")


def run_flower():
    """Run Flower monitoring tool"""
    print("ğŸŒ¸ Starting Flower Task Monitor...")
    print("ğŸ“Š Flower UI will be available at: http://localhost:5555")
    os.system("celery -A src.celery_app flower")


def init_database():
    """Initialize the database"""
    from src.core.database import init_database as init_db
    print("ğŸ—„ï¸  Initializing AutoCurate Database...")
    init_db()
    print("âœ… Database initialization completed!")


async def run_scraping():
    """Run one-time scraping job"""
    from src.agents.website_ingest_agent import run_scheduled_scraping
    
    print("ğŸ•·ï¸  Running website scraping job...")
    await run_scheduled_scraping()
    print("âœ… Scraping completed!")


async def run_processing():
    """Run one-time content processing job"""
    from src.agents.vector_storage_agent import process_pending_content
    
    print("âš™ï¸  Running content processing job...")
    await process_pending_content()
    print("âœ… Content processing completed!")


async def generate_test_summary():
    """Generate a test summary for user ID 1"""
    from src.agents.summary_agent import SummaryAgent
    
    print("ğŸ“ Generating test summary...")
    
    agent = SummaryAgent()
    await agent.initialize()
    
    summary = await agent.generate_personalized_summary(1, "daily_digest")
    
    if summary:
        print("âœ… Test summary generated successfully!")
        print(f"ğŸ“‹ Title: {summary['title']}")
        print(f"ğŸ“Š Word Count: {summary['word_count']}")
        print(f"â±ï¸  Read Time: {summary['read_time_minutes']} minutes")
    else:
        print("âŒ Failed to generate test summary")


def show_status():
    """Show application status"""
    import requests
    from src.config.settings import settings
    
    print("ğŸ“Š AutoCurate Application Status")
    print("=" * 40)
    
    # Check API status
    try:
        response = requests.get(f"http://{settings.app.host}:{settings.app.port}/health", timeout=5)
        if response.status_code == 200:
            print("âœ… API Server: Running")
        else:
            print("âŒ API Server: Error")
    except:
        print("âŒ API Server: Not running")
    
    # Check database
    try:
        from src.core.database import SessionLocal
        from src.models.database import Website
        
        db = SessionLocal()
        website_count = db.query(Website).count()
        db.close()
        
        print(f"âœ… Database: Connected ({website_count} websites)")
    except Exception as e:
        print(f"âŒ Database: Error - {e}")
    
    # Check Redis (if available)
    try:
        import redis
        r = redis.from_url(settings.scheduling.redis_url)
        r.ping()
        print("âœ… Redis: Connected")
    except:
        print("âŒ Redis: Not available")


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="AutoCurate - AI-Powered Knowledge Feed")
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # API server
    subparsers.add_parser('api', help='Run the FastAPI server')
    
    # Background workers
    subparsers.add_parser('worker', help='Run Celery worker for background tasks')
    subparsers.add_parser('scheduler', help='Run Celery beat scheduler')
    subparsers.add_parser('flower', help='Run Flower task monitor')
    
    # Database
    subparsers.add_parser('init-db', help='Initialize the database')
    
    # One-time jobs
    subparsers.add_parser('scrape', help='Run website scraping job')
    subparsers.add_parser('process', help='Run content processing job')
    subparsers.add_parser('test-summary', help='Generate a test summary')
    
    # Utilities
    subparsers.add_parser('status', help='Show application status')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    print("ğŸ§  AutoCurate - AI-Powered Knowledge Feed")
    print("=" * 50)
    
    if args.command == 'api':
        run_api()
    elif args.command == 'worker':
        run_worker()
    elif args.command == 'scheduler':
        run_scheduler()
    elif args.command == 'flower':
        run_flower()
    elif args.command == 'init-db':
        init_database()
    elif args.command == 'scrape':
        asyncio.run(run_scraping())
    elif args.command == 'process':
        asyncio.run(run_processing())
    elif args.command == 'test-summary':
        asyncio.run(generate_test_summary())
    elif args.command == 'status':
        show_status()
    else:
        print(f"âŒ Unknown command: {args.command}")
        parser.print_help()


if __name__ == "__main__":
    main()
